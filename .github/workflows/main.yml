name: Ultimate Website Crawler （Main） 

on:
  repository_dispatch:
  workflow_dispatch:
  #schedule:
    # Runs at 00:05 UTC every Saturday
   # - cron: '5 0 * * 6'

jobs:
  crawl-and-notify:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    permissions:
      contents: write

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        persist-credentials: true

    - name: Initialize environment
      run: |
        sudo timedatectl set-timezone Asia/Shanghai
        export DIR_NAME="webpages-$(TZ='Asia/Shanghai' date +'%Y%m%d')"
        echo "DIR_NAME=$DIR_NAME" >> $GITHUB_ENV
        mkdir -p $DIR_NAME
        echo "🕒 初始化目录完成：$DIR_NAME"

    - name: Advanced website crawling
      run: |
        # 终极防御式抓取参数
        wget --mirror \
             --convert-links \
             --adjust-extension \
             --page-requisites \
             --no-parent \
             --no-check-certificate \
             --user-agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36" \
             --retry-on-http-error=403,429,500-599 \
             --tries=2 \
             --wait=3 \
             --random-wait \
             --span-hosts \
             --domains saoing.com,www.saoing.com \
             --restrict-file-names=windows \
             --reject-regex '\s|%20|^http://[^/]*\s' \
             --exclude-directories='/EIRP,/tmp' \
             --no-directories \
             --level=5 \
             --quota=500m \
             --header="Accept: text/html,application/xhtml+xml" \
             -e robots=off \
             --debug \
             -P $DIR_NAME \
             http://www.saoing.com/ 2>wget-errors.log || true

        # 强制生成有效目录结构
        find $DIR_NAME -type d -exec touch {}/.keep \;

    - name: Content verification
      run: |
        echo "🔍 内容验证报告："
        echo "核心文件检测："
        ls $DIR_NAME/www.saoing.com/index.* 2>/dev/null || echo "未找到index文件"
        
        echo "文件统计："
        find $DIR_NAME -type f | wc -l | xargs echo "总文件数："
        
        echo "错误日志摘要："
        grep -iE 'failed|error|warn' wget-errors.log | head -n 5

        if [ -n "$(find $DIR_NAME -name '*.htm*')" ]; then
          echo "CONTENT_VALID=1" >> $GITHUB_ENV
        else
          echo "CONTENT_VALID=0" >> $GITHUB_ENV
        fi

    - name: Git operations
      run: |
        git config --global user.name "GitHub Archiver"
        git config --global user.email "archive@github.com"
        git remote set-url origin https://${{ github.actor }}:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git

        git add $DIR_NAME
        if ! git commit -m "Archived: $DIR_NAME"; then
          echo "🔄 无新内容变更"
          exit 0  # 允许无变更退出
        fi
        git push

    - name: Smart notification
      if: always()
      env:
        TG_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
        TG_CHAT: ${{ secrets.TELEGRAM_CHAT_ID }}
      run: |
        # 高级通知逻辑
        ERROR_MSG=$(tail -n 10 wget-errors.log | sed 's/%/%25/g')
        FILE_TREE=$(tree -L 2 $DIR_NAME | head -n 5 | sed 's/%/%25/g')
        
        if [ "$CONTENT_VALID" -eq 1 ]; then
          EMOJI="🎉"
          STATUS="成功抓取"
          BUTTON="--inline-keyboard '[[{text: \"浏览目录\", url: \"https://github.com/$GITHUB_REPOSITORY/tree/main/$DIR_NAME\"}]]'"
        else
          EMOJI="⚠️"
          STATUS="部分失败"
          BUTTON=""
        fi

        curl -s -X POST \
          "https://api.telegram.org/bot${TG_TOKEN}/sendMessage" \
          -d chat_id="${TG_CHAT}" \
          -d parse_mode="HTML" \
          -d text="<b>${EMOJI} 抓取报告</b>
          ▫️ 状态: ${STATUS}
          ▫️ 日期: $(date +'%m-%d %H:%M')
          ▫️ 目录: <code>${DIR_NAME}</code>
          ▫️ 文件预览:
          <pre>${FILE_TREE}</pre>
          ▫️ 最新日志:
          <pre>${ERROR_MSG}</pre>" \
          -d reply_markup="${BUTTON}"
