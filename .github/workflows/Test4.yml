name: Daily Website Crawl Gemini

on:
  schedule:
    # Runs at 00:05 UTC every Saturday
    - cron: '5 0 * * 6'
  workflow_dispatch:  # Allows manual triggering


jobs:
  crawl-website:
    runs-on: ubuntu-latest

    # Permissions required to push changes to the repository
    permissions:
      contents: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          persist-credentials: true

      - name: Set up timezone
        run: sudo timedatectl set-timezone Asia/Shanghai

      - name: Set up directory name
        run: |
          DIR_NAME="webpages-$(TZ='Asia/Shanghai' date +'%Y%m%d%H%M')"
          echo "DIR_NAME=$DIR_NAME" >> $GITHUB_ENV
          echo "Creating directory: $DIR_NAME"  # Add debug output

      - name: Crawl website
        run: |
          # Create directory
          mkdir -p "$DIR_NAME"

          # Added --no-robots, --level=inf, retry parameters, user agent, error handling.
          wget --mirror \
               --convert-links \
               --adjust-extension \
               --page-requisites \
               --level=inf \
               --tries=3 \
               --timeout=60 \
               --waitretry=10 \
               --retry-connrefused \
               --user-agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/109.0" \
               --no-check-certificate \
               -P "$DIR_NAME" \
               http://www.saoing.com/ 2>&1 | tee wget.log  # Tee output to log
          echo "Wget complete.  Exit code: $?"
          # Ensure an empty commit is created if nothing was downloaded.
          touch "$DIR_NAME/.gitkeep"  # Create .gitkeep

      - name: Check if any files were downloaded
        id: check_files
        run: |
          FILES_DOWNLOADED=$(find "$DIR_NAME" -type f -not -name ".gitkeep" | wc -l)
          echo "files_downloaded=$FILES_DOWNLOADED" >> $GITHUB_OUTPUT


      - name: Commit and push changes
        if: steps.check_files.outputs.files_downloaded != '0'  # Skip commit if no files
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"

          # Add all files including wget.log
          git add .

          git commit -m "Daily crawl: Update $DIR_NAME"
          git push origin HEAD:${GITHUB_REF}


      - name: Send Telegram notification
        env:
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
        run: |
          # Determine status based on files_downloaded output
          STATUS_MESSAGE="✅ 成功，有内容更新"
          if [ "${{ steps.check_files.outputs.files_downloaded }}" == "0" ]; then
            STATUS_MESSAGE="⚠️ 抓取未成功，无新内容"
          fi

          FILE_INFO=$(du -sh "$DIR_NAME")
          # Create the message
          MESSAGE="网站抓取状态: $STATUS_MESSAGE%0A- 日期: $(TZ='Asia/Shanghai' date +'%Y-%m-%d')%0A- 目录: $DIR_NAME%0A- 目录大小: $FILE_INFO%0A- 日志: https://github.com/$GITHUB_REPOSITORY/actions/runs/$GITHUB_RUN_ID"

          # Send the Telegram notification
          curl -s -X POST "https://api.telegram.org/bot${TELEGRAM_BOT_TOKEN}/sendMessage" -d chat_id="${TELEGRAM_CHAT_ID}" -d text="$MESSAGE"

          echo "Telegram notification sent."

